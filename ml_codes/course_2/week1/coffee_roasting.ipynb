{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 11:43:51.893586: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-08 11:43:51.981404: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-08 11:43:52.356391: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/abrar/miniconda3/envs/tf/lib/\n",
      "2023-03-08 11:43:52.356442: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/abrar/miniconda3/envs/tf/lib/\n",
      "2023-03-08 11:43:52.356445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-08 11:43:52.727040: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-08 11:43:52.742431: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 11:43:52.746639: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 11:43:52.746793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 11:43:53.143591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 11:43:53.143759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 11:43:53.143865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 11:43:53.143976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2110 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Normalization, Input\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_coffee_data():\n",
    "    \"\"\" Creates a coffee roasting data set.\n",
    "        roasting duration: 12-15 minutes is best\n",
    "        temperature range: 175-260C is best\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(2)\n",
    "    # print(rng)\n",
    "    X = rng.random(400).reshape(-1,2)\n",
    "    # print(X)\n",
    "    X[:,1] = X[:,1] * 4 + 11.5          # 12-15 min is best\n",
    "    X[:,0] = X[:,0] * (285-150) + 150  # 350-500 F (175-260 C) is best\n",
    "    Y = np.zeros(len(X))\n",
    "    \n",
    "    i=0\n",
    "    for t,d in X:\n",
    "        y = -3/(260-175)*t + 21\n",
    "        if (t > 175 and t < 260 and d > 12 and d < 15 and d<=y ):\n",
    "            Y[i] = 1\n",
    "        else:\n",
    "            Y[i] = 0\n",
    "        i += 1\n",
    "\n",
    "    return (X, Y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_coffee_data()\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Max, Min pre normalization: 284.99, 151.32\n",
      "Duration    Max, Min pre normalization: 15.45, 11.51\n",
      "Temperature Max, Min post normalization: 1.66, -1.69\n",
      "Duration    Max, Min post normalization: 1.79, -1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 11:43:59.440567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 11:43:59.440876: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 11:43:59.441037: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 11:43:59.441415: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 11:43:59.441558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 11:43:59.441673: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 11:43:59.441846: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 11:43:59.441967: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-08 11:43:59.442070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2110 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temperature Max, Min pre normalization: {np.max(X[:,0]):0.2f}, {np.min(X[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min pre normalization: {np.max(X[:,1]):0.2f}, {np.min(X[:,1]):0.2f}\")\n",
    "norm_l = tf.keras.layers.Normalization(axis=-1)\n",
    "norm_l.adapt(X)  # learns mean, variance\n",
    "Xn = norm_l(X)\n",
    "print(f\"Temperature Max, Min post normalization: {np.max(Xn[:,0]):0.2f}, {np.min(Xn[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min post normalization: {np.max(Xn[:,1]):0.2f}, {np.min(Xn[:,1]):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2)\n",
      "[[185.32  12.69]\n",
      " [259.92  11.87]\n",
      " [185.32  12.69]\n",
      " [259.92  11.87]\n",
      " [185.32  12.69]\n",
      " [259.92  11.87]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[185.32,  12.69], [259.92,  11.87]])\n",
    "arr_4 = np.tile(arr, (3, 1))\n",
    "print(arr_4.shape)\n",
    "print(arr_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 2) (200000, 1)\n"
     ]
    }
   ],
   "source": [
    "## Increasing training data to decrease training iterations(epochs)\n",
    "Xt = np.tile(Xn,(1000,1))\n",
    "Yt= np.tile(Y,(1000,1))   \n",
    "print(Xt.shape, Yt.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234) # Needed for getting similar output everytime the code is run\n",
    "model = Sequential([\n",
    "    Input(shape=(2,)),\n",
    "    Dense(units=3, activation='relu', name='layer_1'),\n",
    "    Dense(units=1, activation='sigmoid', name='layer_2')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer_1 (Dense)             (None, 3)                 9         \n",
      "                                                                 \n",
      " layer_2 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # Checking the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:\n",
      "[[ 0.29121268  0.59385514  0.9740267 ]\n",
      " [-0.8101201  -0.4449491  -0.831807  ]]\n",
      "B1:\n",
      "[0. 0. 0.]\n",
      "W2:\n",
      "[[ 0.29121268  0.59385514  0.9740267 ]\n",
      " [-0.8101201  -0.4449491  -0.831807  ]]\n",
      "B2:\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "W1, B1 = model.get_layer(\"layer_1\").get_weights()\n",
    "print(f\"W1:\\n{W1}\\nB1:\\n{B1}\")\n",
    "W2, B2 = model.get_layer(\"layer_1\").get_weights()\n",
    "print(f\"W2:\\n{W2}\\nB2:\\n{B2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 11:44:13.915341: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-08 11:44:13.916840: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f7522587c10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-08 11:44:13.916855: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2023-03-08 11:44:13.920266: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-08 11:44:14.012551: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 7s 976us/step - loss: 0.1120\n",
      "Epoch 2/10\n",
      "6250/6250 [==============================] - 6s 963us/step - loss: 0.0260\n",
      "Epoch 3/10\n",
      "6250/6250 [==============================] - 6s 964us/step - loss: 0.0148\n",
      "Epoch 4/10\n",
      "6250/6250 [==============================] - 6s 967us/step - loss: 0.0095\n",
      "Epoch 5/10\n",
      "6250/6250 [==============================] - 6s 967us/step - loss: 0.0063\n",
      "Epoch 6/10\n",
      "6250/6250 [==============================] - 6s 964us/step - loss: 0.0044\n",
      "Epoch 7/10\n",
      "6250/6250 [==============================] - 6s 963us/step - loss: 0.0032\n",
      "Epoch 8/10\n",
      "6250/6250 [==============================] - 6s 1ms/step - loss: 0.0023\n",
      "Epoch 9/10\n",
      "6250/6250 [==============================] - 6s 1ms/step - loss: 0.0019\n",
      "Epoch 10/10\n",
      "6250/6250 [==============================] - 6s 987us/step - loss: 0.0012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f766f64b340>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling model\n",
    "model.compile(\n",
    "    loss=BinaryCrossentropy(),\n",
    "    optimizer= Adam(learning_rate=0.01)\n",
    ")\n",
    "\n",
    "# Training Model\n",
    "model.fit(Xt, Yt, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:\n",
      "[[ 7.843036    8.21372     8.875285  ]\n",
      " [ 0.43905523  6.9482327  -9.652563  ]]\n",
      "B1:\n",
      "[ 9.380385   1.9992826 -2.4938345]\n",
      "W2:\n",
      "[[ 7.843036    8.21372     8.875285  ]\n",
      " [ 0.43905523  6.9482327  -9.652563  ]]\n",
      "B2:\n",
      "[ 9.380385   1.9992826 -2.4938345]\n"
     ]
    }
   ],
   "source": [
    "W1, B1 = model.get_layer(\"layer_1\").get_weights()\n",
    "print(f\"W1:\\n{W1}\\nB1:\\n{B1}\")\n",
    "W2, B2 = model.get_layer(\"layer_1\").get_weights()\n",
    "print(f\"W2:\\n{W2}\\nB2:\\n{B2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "predictions = \n",
      " [[1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "## Testing the model\n",
    "X_test = np.array([\n",
    "    [200,13.9],  # postive example\n",
    "    [200,17]])   # negative example\n",
    "X_testn = norm_l(X_test)\n",
    "predictions = model.predict(X_testn)\n",
    "print(\"predictions = \\n\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
